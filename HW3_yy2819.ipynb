{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3_yy2819.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"8b5s6dLcP-PJ","colab_type":"text"},"cell_type":"markdown","source":["**Advanced Machine Learning**  \n","(GR5242)Fall 2017  \n","\n","*Author: Yang Yang (yy2819)*  \n","*Date: Oct.31 2018*\n","\n","# Homework 3\n","## Problem 1:  Short questions\n","\n","### (a) Suppose  you  have  an  algorithm  that,  when  run $n$ times,  generates $n$ independent samples from a density $p$. How do you generate $n$ independent points distributed uniformly on the area under the curve $p$?\n","### Ans:\n","After generates $n$ independent samples from a density $p$ as $x$, then just draw samples from $Unif(0,p(x))$ from the every $x$ as $y$.\n","\n","### (b)  A logistic regression classifier σ($\\mathbf{v^tx−c}$)is trained by fitting the vector $v$ and offset $c$ using an optimization algorithm.  How does overfitting occur?\n","### Ans:\n","Even the classfication result on training set will not alter, the regression will unlimited increase $|v|$ to decrease the loss, which cause the overfitting.\n","### (c)  Suppose the variables Z1,...,Zn in the graphical model below are unobserved.  Are Xn and X2 dependent or independent?  Please explain your answer\n","### Ans:\n","They are dependent, unless any one of  $Z2,...,Zn$ is observed."]},{"metadata":{"id":"CPUSo3OkS-XQ","colab_type":"text"},"cell_type":"markdown","source":["## Problem 2:  XOR network\n","![alt text](https://raw.githubusercontent.com/jokerkeny/playground/master/fig/prob2xor.png)"]},{"metadata":{"id":"9IqgADUNalZg","colab_type":"text"},"cell_type":"markdown","source":["## Problem 3:  Dirichlet distributions\n","I think it consist of onedata point in category 3, because the posterior distribution's center has moved towards Cat 3. Based on the Bayesian Formula, the likelihood function is a multinomial function, which would be higher if the data point belongs to Categorical 3."]},{"metadata":{"id":"yz-GxS4HbIlS","colab_type":"text"},"cell_type":"markdown","source":["## Problem 4:  Neural network classifier\n","$\\mathbf{w^tx-c}=\\frac{7}{2\\sqrt 2}$  \n","$\\mathbf{w^tx'-c}=\\frac{1}{2\\sqrt 2}$  "]},{"metadata":{"id":"igEDC8uMbIax","colab_type":"text"},"cell_type":"markdown","source":["## Problem 5:  Rejection and importance sampling\n","### (a) What is the optimal choice for $M$ if we wish to keep the number of rejected samples as small as possible?\n","The choice of $M$ should satisfy$\\frac pM<q=1 $, and we wish to keep the number of rejected samples as small as possible,  \n","$\\therefore M=max(\\frac pq)=2$\n","### (b) Compute the acceptance probability for the rejection sampling procedure (for the optimal choice of M).If we wish to obtain $m$ samples from the rejection sampling procedure, how many times $n$ do we have to sample from the proposal distribution on average?\n","$$Area\\ of\\ \\tilde p=\\int_0^1\\tilde pdx=\\int_0^1xdx=\\frac12\\\\\n","Area\\ of\\ q=1\\\\\n","\\therefore\\ Acceptance\\ rate=\\frac12/1=\\frac12\\\\\n","\\therefore E(n)=\\frac m{\\frac12}=2m$$"]},{"metadata":{"id":"aduGloIDf24C","colab_type":"text"},"cell_type":"markdown","source":["### (c) Now suppose we use importance sampling rather than rejection sampling, again with uniform proposal distribution. What is the variance of the importance sampling estimate of the mean, for $n$ samples?2\n","To use the importance sampling estimate of the mean, for $n$ samples, we use \n","$$\\bar X=E_p(X)=E_q(\\frac{Xp(X)}{q(X)})\\approx \\frac1n\\sum_{i=1}^n \\frac{x_ip(x_i)}{q(x_i)}= \\frac1n\\sum_{i=1}^n2x_i^2\\\\\n","E(\\bar X)=E_p(X)=\\int_0^1 2x^2dx=\\frac23\\\\\n","Var(\\bar X)\n","=\\frac1{n^2}\\sum_{i=1}^n Var_q(2X^2)\n","=\\frac4{n} Var_q(X^2)\n","=\\frac4{n} E_q\\left((X^2-E_q(X^2)^2\\right)\n","=\\frac4{n} [E_q(X^4)-E_q(X^2)^2]\n","=\\frac4{n} (\\frac15-\\frac19)=\\frac{16}{45n}$$"]},{"metadata":{"id":"1Bj6smBIjZoV","colab_type":"text"},"cell_type":"markdown","source":["##Problem 6:  Rejection sampling without rejection"]},{"metadata":{"id":"WpZS8jb_mK8p","colab_type":"text"},"cell_type":"markdown","source":["### (a) Find the density of $X_i|Z_i=R$.Hint:Proceed in the same way as above.\n","$$P(X_i≤x|R)=P(X_i≤x|U_i>\\frac{p(X_i)}{kr(X_i)}) \n","=\\frac {P(X_i≤x,U_i>\\frac{p(X_i)}{kr(X_i)})}    {P(U_i>\\frac{p(X_i)}{kr(X_i)})} \\\\\n","=\\frac{\\int^x_{-\\infty}\\left[ \\int^1_{p(x_i)/kr(x_i)}dy\\right]r(x_i)dx}\n","{\\int_{-\\infty}^{\\infty}\\left[ \\int^1_{p(x_i)/kr(x_i)}dy\\right]r(x_i)dx}\n","=\\frac  {\\frac1k\\int_{-\\infty}^x \\left(kr(x_i)-p(x_i)\\right)dx_i     }\n","{\\frac1k\\int_{-\\infty}^{\\infty}\\left(kr(x_i)-p(x_i)\\right)dx_i  }\\\\\n","\\because \\int_{-\\infty}^{\\infty}\\left(kr(x_i)-p(x_i)\\right)dx_i)=k-1\\\\\n","=\\int_{-\\infty}^x\\left(kr(x_i)-p(x_i)\\right)dx_i  /(k-1)\n","$$\n","$$\\therefore X_i|Z_i=R\\sim \\frac{kr(\\cdot)-p(\\cdot)}{(k-1)}$$"]},{"metadata":{"id":"Nt2ncbYFmQVx","colab_type":"text"},"cell_type":"markdown","source":["###  b)  Consider the estimator $δ$ Explain (carefully) how $δ$ can be interpreted as an importance sampling estimate of $θ$"]},{"metadata":{"id":"MwaV03fsuD1B","colab_type":"text"},"cell_type":"markdown","source":["Using the formula of importance sampling, \n","$$\\mathbb E_p[h(x)]\\approx\\frac1m\\sum^m_{i=1}h(X_i)\\frac {p(X_i)}{q(X_i)}$$\n","here we take $q(\\cdot)$ as $$\\frac{kr(\\cdot)-p(\\cdot)}{(k-1)}$$\n","then we have $$E_p[h(x)]\\approx\\frac1m\\sum^m_{i=1}h(X_i)\\frac {(k-1)p(X_i)}{kr(\\cdot)-p(\\cdot)}$$\n","then this consititute the second term in the estimate $\\delta$"]},{"metadata":{"id":"NT00RJhxP6gJ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}